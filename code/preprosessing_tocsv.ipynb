{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d58c5011",
   "metadata": {},
   "source": [
    "### دریافت همه داده های راه رفتن 5 نفر\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e66697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "در حال پردازش LOG2.TXT...\n",
      "در حال پردازش LOG7.TXT...\n",
      "در حال پردازش LOG8.TXT...\n",
      "در حال پردازش LOG10.TXT...\n",
      "در حال پردازش LOG13.TXT...\n",
      "\n",
      "df_combined shape :  (87404, 15)\n",
      "df_clean shape :   (87394, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.signal import butter, filtfilt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# لیست فایل‌ها\n",
    "file_list = ['LOG2.TXT', 'LOG7.TXT', 'LOG8.TXT', 'LOG10.TXT', 'LOG13.TXT']\n",
    "\n",
    "# ستون‌های خروجی\n",
    "columns = [\n",
    "    'Time', 'angle',\n",
    "    'MPU1_Acc_X', 'MPU1_Acc_Y', 'MPU1_Acc_Z',\n",
    "    'MPU1_Gyro_X', 'MPU1_Gyro_Y', 'MPU1_Gyro_Z',\n",
    "    'MPU2_Acc_X', 'MPU2_Acc_Y', 'MPU2_Acc_Z',\n",
    "    'MPU2_Gyro_X', 'MPU2_Gyro_Y', 'MPU2_Gyro_Z'\n",
    "]\n",
    "\n",
    "# ستون‌های ویژگی برای LSTM\n",
    "feature_columns = [\n",
    "    'MPU1_Acc_X', 'MPU1_Acc_Y', 'MPU1_Acc_Z',\n",
    "    'MPU1_Gyro_X', 'MPU1_Gyro_Y', 'MPU1_Gyro_Z',\n",
    "    'MPU2_Acc_X', 'MPU2_Acc_Y', 'MPU2_Acc_Z',\n",
    "    'MPU2_Gyro_X', 'MPU2_Gyro_Y', 'MPU2_Gyro_Z'\n",
    "]\n",
    "\n",
    "all_dfs = []  # لیست برای نگهداری تمام دیتافریم‌ها\n",
    "\n",
    "# تابع پردازش یک فایل\n",
    "def parse_file(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line_num, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # استخراج زمان\n",
    "        time_match = re.search(r'Time:\\s*(\\d+)\\s*ms', line)\n",
    "        time = int(time_match.group(1)) if time_match else None\n",
    "\n",
    "        # استخراج زاویه\n",
    "        angle_match = re.search(r'Angle: ([\\-\\d.]+)Â°', line)\n",
    "        if angle_match:\n",
    "            angle=float(angle_match.group(1))\n",
    "        else:\n",
    "            angle=np.nan\n",
    "\n",
    "        # استخراج MPU1 Acc — انواع فرمت\n",
    "        mpu1_acc_match = re.search(r'MPU1(?: Acc| A cc)?\\s*:\\s*([-\\d.]+),\\s*([-\\d.]+),\\s*([-\\d.]+)', line)\n",
    "        \n",
    "        # استخراج MPU1 Gyro — با یا بدون \"MPU1\" قبل از Gyro\n",
    "        mpu1_gyro_match = re.search(r'MPU1.*?Gyro\\s*:\\s*([-\\d.]+),\\s*([-\\d.]+),\\s*([-\\d.]+)', line)\n",
    "        if not mpu1_gyro_match:\n",
    "            mpu1_gyro_match = re.search(r'Gyro\\s*:\\s*([-\\d.]+),\\s*([-\\d.]+),\\s*([-\\d.]+)', line.split('||')[1] if '||' in line else line)\n",
    "\n",
    "        # استخراج MPU2 Acc\n",
    "        mpu2_acc_match = re.search(r'MPU2 Acc\\s*:\\s*([-\\d.]+),\\s*([-\\d.]+),\\s*([-\\d.]+)', line)\n",
    "        \n",
    "        # استخراج MPU2 Gyro\n",
    "        mpu2_gyro_match = re.search(r'MPU2.*?Gyro\\s*:\\s*([-\\d.]+),\\s*([-\\d.]+),\\s*([-\\d.]+)', line)\n",
    "\n",
    "        def extract_values(match):\n",
    "            if match:\n",
    "                try:\n",
    "                    return [float(match.group(i)) for i in range(1, 4)]\n",
    "                except (IndexError, ValueError):\n",
    "                    return [np.nan] * 3\n",
    "            return [np.nan] * 3\n",
    "\n",
    "        mpu1_acc = extract_values(mpu1_acc_match)\n",
    "        mpu1_gyro = extract_values(mpu1_gyro_match)\n",
    "        mpu2_acc = extract_values(mpu2_acc_match)\n",
    "        mpu2_gyro = extract_values(mpu2_gyro_match)\n",
    "\n",
    "        data.append([\n",
    "            time, angle,\n",
    "            mpu1_acc[0], mpu1_acc[1], mpu1_acc[2],\n",
    "            mpu1_gyro[0], mpu1_gyro[1], mpu1_gyro[2],\n",
    "            mpu2_acc[0], mpu2_acc[1], mpu2_acc[2],\n",
    "            mpu2_gyro[0], mpu2_gyro[1], mpu2_gyro[2]\n",
    "        ])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# خواندن و پردازش تمام فایل‌ها\n",
    "for filename in file_list:\n",
    "    print(f\"در حال پردازش {filename}...\")\n",
    "    df = parse_file(filename)\n",
    "    df['source'] = filename  # برای تشخیص منبع (اختیاری)\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# ترکیب تمام دیتافریم‌ها\n",
    "df_combined = pd.concat(all_dfs, ignore_index=True)\n",
    "print(\"\\ndf_combined shape : \", df_combined.shape)\n",
    "\n",
    "# حذف NaN و آماده‌سازی داده‌ها\n",
    "df_clean = df_combined.dropna().reset_index(drop=True)\n",
    "print(\"df_clean shape :  \", df_clean.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b46c9d3",
   "metadata": {},
   "source": [
    "### فیلتر کردن و کلیپ کردن "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43aeee16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying low-pass filter to sensor signals...\n",
      "Filtering completed.\n",
      "clipping completed.\n",
      "\n",
      "df_filtered shape: (87394, 12)\n"
     ]
    }
   ],
   "source": [
    "def low_pass_butter(signal, cutoff=10, fs=100, order=2):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "\n",
    "# After creating df_clean\n",
    "print(\"Applying low-pass filter to sensor signals...\")\n",
    "\n",
    "# Define cutoff frequency and sampling rate\n",
    "fs = 100      # Hz\n",
    "cutoff = 12   # Hz\n",
    "\n",
    "\n",
    "df_filtered = pd.DataFrame()\n",
    "\n",
    "for col in feature_columns:\n",
    "    df_filtered[col] = low_pass_butter(df_clean[col].values, cutoff=cutoff, fs=fs, order=2)\n",
    "\n",
    "print(\"Filtering completed.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# اعمال حد مجاز [-200, 200] روی تمام ژیروسکوپ‌ها\n",
    "for col in ['MPU1_Gyro_X', 'MPU1_Gyro_Y', 'MPU1_Gyro_Z','MPU2_Gyro_X', 'MPU2_Gyro_Y', 'MPU2_Gyro_Z']:\n",
    "    df_filtered[col] = np.clip(df_filtered[col], -200, 200)\n",
    "\n",
    "# اعمال حد مجاز [-10, 10] روی تمام ژیروسکوپ‌ها\n",
    "for col in ['MPU1_Acc_X', 'MPU1_Acc_Y', 'MPU1_Acc_Z', 'MPU2_Acc_X', 'MPU2_Acc_Y', 'MPU2_Acc_Z']:\n",
    "    df_filtered[col] = np.clip(df_filtered[col], -10, 10)\n",
    "\n",
    "print(\"clipping completed.\")\n",
    "\n",
    "print(\"\\ndf_filtered shape:\",df_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd58635",
   "metadata": {},
   "source": [
    "### پنجره بندی و استاندارد سازی "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bc50ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Total number of windows: 1164\n",
      " Input data shape (X_windows):(samples, time steps, features) → (1164, 150, 12)\n",
      " Label shape (y_windows): (1164,)\n"
     ]
    }
   ],
   "source": [
    "# استانداردسازی ویژگی‌ها\n",
    "\n",
    "# df_filtered shape: (87394, 12)\n",
    "scaler = StandardScaler()\n",
    "X_data = scaler.fit_transform(df_filtered[feature_columns].values)  # (T, 12)\n",
    "\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_data = y_scaler.fit_transform(df_clean['angle'].values.reshape(-1, 1)).flatten()\n",
    "# تنظیمات پنجره\n",
    "window_size = 150   # ~1 ثانیه با 100Hz\n",
    "step_size = 75      # 50% هم‌پوشانی\n",
    "\n",
    "# تابع پنجره‌بندی\n",
    "def create_windows_with_labels(X, y, window_size, step_size):\n",
    "    X_windows = []\n",
    "    y_windows = []\n",
    "    for i in range(0, len(X) - window_size + 1, step_size):\n",
    "        X_windows.append(X[i:i + window_size])\n",
    "        y_windows.append(y[i + window_size - 1])  # برچسب آخرین نمونه در پنجره\n",
    "    return np.array(X_windows), np.array(y_windows)\n",
    "\n",
    "# ایجاد پنجره‌ها\n",
    "X_windows, y_windows = create_windows_with_labels(X_data, y_data, window_size, step_size)\n",
    "\n",
    "print(f\"\\n Total number of windows: {X_windows.shape[0]}\")\n",
    "print(f\" Input data shape (X_windows):(samples, time steps, features) → {X_windows.shape}\")\n",
    "print(f\" Label shape (y_windows): {y_windows.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b18459e",
   "metadata": {},
   "source": [
    "### ساخت شبکه LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd6271eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"LSTM_reg_final\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"LSTM_reg_final\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m19,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,801</span> (206.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m52,801\u001b[0m (206.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,801</span> (206.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,801\u001b[0m (206.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, ReLU\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "lambda_loss_amount = 0.0005\n",
    "\n",
    "\n",
    "def build_lstm_model2(input_shape, n_hidden):\n",
    "    inputs = Input(shape=input_shape, name=\"input\")\n",
    "\n",
    "    # یک لایه LSTM که فقط آخرین خروجی را برگرداند\n",
    "\n",
    "    # Stacked LSTM layers\n",
    "    x = LSTM(n_hidden, return_sequences=True)(inputs)   # 1st LSTM layer\n",
    "    x = LSTM(n_hidden, return_sequences=False)(x)\n",
    "\n",
    "    # x = LSTM(n_hidden, return_sequences=False)(inputs)\n",
    "\n",
    "    # خروجی نهایی فقط یک عدد است (مثلاً y_t)\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"LSTM_reg_final\")\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "final_model = build_lstm_model2(input_shape=(X_windows.shape[1],X_windows.shape[2]), n_hidden=64)\n",
    "\n",
    "final_model.summary()\n",
    "\n",
    "\n",
    "plot_model(final_model, show_shapes=True , dpi=80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6872cc7c",
   "metadata": {},
   "source": [
    "### آموزش شبکه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b849a2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.9867 - mae: 0.7996\n",
      "Epoch 1: loss improved from inf to 0.99227, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - loss: 0.9871 - mae: 0.7994\n",
      "Epoch 2/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8569 - mae: 0.7401\n",
      "Epoch 2: loss improved from 0.99227 to 0.85879, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.8570 - mae: 0.7396\n",
      "Epoch 3/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7588 - mae: 0.6833\n",
      "Epoch 3: loss improved from 0.85879 to 0.74344, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.7579 - mae: 0.6830\n",
      "Epoch 4/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6310 - mae: 0.6298\n",
      "Epoch 4: loss improved from 0.74344 to 0.63273, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.6311 - mae: 0.6294\n",
      "Epoch 5/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.5508 - mae: 0.5740\n",
      "Epoch 5: loss improved from 0.63273 to 0.51909, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.5489 - mae: 0.5733\n",
      "Epoch 6/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4315 - mae: 0.5125\n",
      "Epoch 6: loss improved from 0.51909 to 0.42190, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.4309 - mae: 0.5121\n",
      "Epoch 7/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3651 - mae: 0.4688\n",
      "Epoch 7: loss improved from 0.42190 to 0.36022, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.3649 - mae: 0.4688\n",
      "Epoch 8/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3228 - mae: 0.4394\n",
      "Epoch 8: loss improved from 0.36022 to 0.31828, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.3225 - mae: 0.4397\n",
      "Epoch 9/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2889 - mae: 0.4203\n",
      "Epoch 9: loss improved from 0.31828 to 0.28364, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.2886 - mae: 0.4197\n",
      "Epoch 10/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2650 - mae: 0.3900\n",
      "Epoch 10: loss improved from 0.28364 to 0.25041, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.2641 - mae: 0.3896\n",
      "Epoch 11/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2265 - mae: 0.3578\n",
      "Epoch 11: loss improved from 0.25041 to 0.22335, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.2263 - mae: 0.3577\n",
      "Epoch 12/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2057 - mae: 0.3381\n",
      "Epoch 12: loss improved from 0.22335 to 0.20080, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.2051 - mae: 0.3377\n",
      "Epoch 13/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1998 - mae: 0.3189\n",
      "Epoch 13: loss improved from 0.20080 to 0.18240, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.1988 - mae: 0.3189\n",
      "Epoch 14/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1651 - mae: 0.2985\n",
      "Epoch 14: loss improved from 0.18240 to 0.16611, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.1652 - mae: 0.2989\n",
      "Epoch 15/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1456 - mae: 0.2853\n",
      "Epoch 15: loss improved from 0.16611 to 0.15315, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.1465 - mae: 0.2860\n",
      "Epoch 16/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1349 - mae: 0.2690\n",
      "Epoch 16: loss improved from 0.15315 to 0.13842, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.1351 - mae: 0.2695\n",
      "Epoch 17/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1266 - mae: 0.2677\n",
      "Epoch 17: loss improved from 0.13842 to 0.12857, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.1268 - mae: 0.2677\n",
      "Epoch 18/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1073 - mae: 0.2515\n",
      "Epoch 18: loss improved from 0.12857 to 0.11704, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.1078 - mae: 0.2517\n",
      "Epoch 19/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1149 - mae: 0.2499\n",
      "Epoch 19: loss improved from 0.11704 to 0.10962, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.1146 - mae: 0.2499\n",
      "Epoch 20/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1090 - mae: 0.2487\n",
      "Epoch 20: loss improved from 0.10962 to 0.10256, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.1083 - mae: 0.2478\n",
      "Epoch 21/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0970 - mae: 0.2377\n",
      "Epoch 21: loss improved from 0.10256 to 0.09724, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0971 - mae: 0.2376\n",
      "Epoch 22/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0992 - mae: 0.2347\n",
      "Epoch 22: loss improved from 0.09724 to 0.09522, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0987 - mae: 0.2344\n",
      "Epoch 23/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0798 - mae: 0.2182\n",
      "Epoch 23: loss improved from 0.09522 to 0.09017, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0805 - mae: 0.2188\n",
      "Epoch 24/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0811 - mae: 0.2202\n",
      "Epoch 24: loss improved from 0.09017 to 0.08603, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0814 - mae: 0.2204\n",
      "Epoch 25/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0831 - mae: 0.2247\n",
      "Epoch 25: loss improved from 0.08603 to 0.08327, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0831 - mae: 0.2244\n",
      "Epoch 26/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0831 - mae: 0.2204\n",
      "Epoch 26: loss improved from 0.08327 to 0.08068, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0829 - mae: 0.2201\n",
      "Epoch 27/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0853 - mae: 0.2232\n",
      "Epoch 27: loss improved from 0.08068 to 0.07957, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0849 - mae: 0.2228\n",
      "Epoch 28/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0776 - mae: 0.2118\n",
      "Epoch 28: loss improved from 0.07957 to 0.07688, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0775 - mae: 0.2118\n",
      "Epoch 29/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0710 - mae: 0.2071\n",
      "Epoch 29: loss improved from 0.07688 to 0.07466, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0712 - mae: 0.2072\n",
      "Epoch 30/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0690 - mae: 0.2032\n",
      "Epoch 30: loss improved from 0.07466 to 0.07307, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0692 - mae: 0.2035\n",
      "Epoch 31/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0709 - mae: 0.2036\n",
      "Epoch 31: loss improved from 0.07307 to 0.07098, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0709 - mae: 0.2036\n",
      "Epoch 32/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0700 - mae: 0.2073\n",
      "Epoch 32: loss improved from 0.07098 to 0.07001, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0700 - mae: 0.2070\n",
      "Epoch 33/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0671 - mae: 0.1970\n",
      "Epoch 33: loss improved from 0.07001 to 0.06826, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0671 - mae: 0.1973\n",
      "Epoch 34/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0634 - mae: 0.1924\n",
      "Epoch 34: loss improved from 0.06826 to 0.06697, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0636 - mae: 0.1927\n",
      "Epoch 35/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0629 - mae: 0.1955\n",
      "Epoch 35: loss improved from 0.06697 to 0.06583, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0631 - mae: 0.1957\n",
      "Epoch 36/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0612 - mae: 0.1911\n",
      "Epoch 36: loss improved from 0.06583 to 0.06514, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0614 - mae: 0.1914\n",
      "Epoch 37/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0681 - mae: 0.1990\n",
      "Epoch 37: loss did not improve from 0.06514\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0680 - mae: 0.1990\n",
      "Epoch 38/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0676 - mae: 0.2007\n",
      "Epoch 38: loss improved from 0.06514 to 0.06333, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0674 - mae: 0.2003\n",
      "Epoch 39/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0619 - mae: 0.1898\n",
      "Epoch 39: loss improved from 0.06333 to 0.06143, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0619 - mae: 0.1898\n",
      "Epoch 40/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0603 - mae: 0.1916\n",
      "Epoch 40: loss improved from 0.06143 to 0.06101, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0603 - mae: 0.1915\n",
      "Epoch 41/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0573 - mae: 0.1880\n",
      "Epoch 41: loss improved from 0.06101 to 0.05892, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0574 - mae: 0.1879\n",
      "Epoch 42/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0546 - mae: 0.1792\n",
      "Epoch 42: loss improved from 0.05892 to 0.05803, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0548 - mae: 0.1796\n",
      "Epoch 43/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0546 - mae: 0.1818\n",
      "Epoch 43: loss improved from 0.05803 to 0.05782, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0548 - mae: 0.1820\n",
      "Epoch 44/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0597 - mae: 0.1894\n",
      "Epoch 44: loss improved from 0.05782 to 0.05677, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0595 - mae: 0.1892\n",
      "Epoch 45/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0523 - mae: 0.1774\n",
      "Epoch 45: loss improved from 0.05677 to 0.05498, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0526 - mae: 0.1778\n",
      "Epoch 46/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0548 - mae: 0.1807\n",
      "Epoch 46: loss did not improve from 0.05498\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0549 - mae: 0.1807\n",
      "Epoch 47/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0552 - mae: 0.1828\n",
      "Epoch 47: loss improved from 0.05498 to 0.05457, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0552 - mae: 0.1825\n",
      "Epoch 48/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0497 - mae: 0.1720\n",
      "Epoch 48: loss improved from 0.05457 to 0.05246, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0498 - mae: 0.1723\n",
      "Epoch 49/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0524 - mae: 0.1777\n",
      "Epoch 49: loss improved from 0.05246 to 0.05200, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0524 - mae: 0.1776\n",
      "Epoch 50/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0509 - mae: 0.1756\n",
      "Epoch 50: loss improved from 0.05200 to 0.05137, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0509 - mae: 0.1755\n",
      "Epoch 51/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0510 - mae: 0.1755\n",
      "Epoch 51: loss did not improve from 0.05137\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0511 - mae: 0.1756\n",
      "Epoch 52/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0506 - mae: 0.1771\n",
      "Epoch 52: loss improved from 0.05137 to 0.05101, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0506 - mae: 0.1770\n",
      "Epoch 53/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0501 - mae: 0.1727\n",
      "Epoch 53: loss improved from 0.05101 to 0.05026, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0501 - mae: 0.1728\n",
      "Epoch 54/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0509 - mae: 0.1752\n",
      "Epoch 54: loss improved from 0.05026 to 0.04890, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0507 - mae: 0.1750\n",
      "Epoch 55/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0437 - mae: 0.1648\n",
      "Epoch 55: loss improved from 0.04890 to 0.04821, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0443 - mae: 0.1654\n",
      "Epoch 56/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0453 - mae: 0.1644\n",
      "Epoch 56: loss improved from 0.04821 to 0.04736, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0455 - mae: 0.1646\n",
      "Epoch 57/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0490 - mae: 0.1715\n",
      "Epoch 57: loss improved from 0.04736 to 0.04680, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0489 - mae: 0.1712\n",
      "Epoch 58/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0500 - mae: 0.1768\n",
      "Epoch 58: loss improved from 0.04680 to 0.04623, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0496 - mae: 0.1756\n",
      "Epoch 59/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0462 - mae: 0.1657\n",
      "Epoch 59: loss did not improve from 0.04623\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0462 - mae: 0.1658\n",
      "Epoch 60/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0483 - mae: 0.1706\n",
      "Epoch 60: loss improved from 0.04623 to 0.04610, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0482 - mae: 0.1704\n",
      "Epoch 61/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0458 - mae: 0.1669\n",
      "Epoch 61: loss improved from 0.04610 to 0.04455, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0458 - mae: 0.1667\n",
      "Epoch 62/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0432 - mae: 0.1610\n",
      "Epoch 62: loss improved from 0.04455 to 0.04398, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0433 - mae: 0.1611\n",
      "Epoch 63/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0454 - mae: 0.1674\n",
      "Epoch 63: loss improved from 0.04398 to 0.04388, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0453 - mae: 0.1672\n",
      "Epoch 64/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0420 - mae: 0.1587\n",
      "Epoch 64: loss improved from 0.04388 to 0.04342, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0421 - mae: 0.1590\n",
      "Epoch 65/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0387 - mae: 0.1539\n",
      "Epoch 65: loss improved from 0.04342 to 0.04233, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0391 - mae: 0.1546\n",
      "Epoch 66/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0414 - mae: 0.1580\n",
      "Epoch 66: loss did not improve from 0.04233\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0414 - mae: 0.1581\n",
      "Epoch 67/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0371 - mae: 0.1491\n",
      "Epoch 67: loss improved from 0.04233 to 0.04108, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0376 - mae: 0.1501\n",
      "Epoch 68/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0409 - mae: 0.1592\n",
      "Epoch 68: loss did not improve from 0.04108\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0409 - mae: 0.1591\n",
      "Epoch 69/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0381 - mae: 0.1531\n",
      "Epoch 69: loss did not improve from 0.04108\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0385 - mae: 0.1539\n",
      "Epoch 70/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0407 - mae: 0.1558\n",
      "Epoch 70: loss did not improve from 0.04108\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0409 - mae: 0.1562\n",
      "Epoch 71/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0387 - mae: 0.1538\n",
      "Epoch 71: loss improved from 0.04108 to 0.03990, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0387 - mae: 0.1539\n",
      "Epoch 72/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0403 - mae: 0.1539\n",
      "Epoch 72: loss improved from 0.03990 to 0.03937, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0402 - mae: 0.1539\n",
      "Epoch 73/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0382 - mae: 0.1499\n",
      "Epoch 73: loss improved from 0.03937 to 0.03873, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0382 - mae: 0.1501\n",
      "Epoch 74/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0387 - mae: 0.1526\n",
      "Epoch 74: loss improved from 0.03873 to 0.03832, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0386 - mae: 0.1525\n",
      "Epoch 75/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0367 - mae: 0.1508\n",
      "Epoch 75: loss improved from 0.03832 to 0.03787, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0369 - mae: 0.1509\n",
      "Epoch 76/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0377 - mae: 0.1510\n",
      "Epoch 76: loss improved from 0.03787 to 0.03720, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0377 - mae: 0.1509\n",
      "Epoch 77/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0397 - mae: 0.1575\n",
      "Epoch 77: loss did not improve from 0.03720\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0396 - mae: 0.1572\n",
      "Epoch 78/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0355 - mae: 0.1472\n",
      "Epoch 78: loss improved from 0.03720 to 0.03651, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0356 - mae: 0.1473\n",
      "Epoch 79/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0350 - mae: 0.1438\n",
      "Epoch 79: loss did not improve from 0.03651\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0351 - mae: 0.1441\n",
      "Epoch 80/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0371 - mae: 0.1494\n",
      "Epoch 80: loss improved from 0.03651 to 0.03622, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0371 - mae: 0.1492\n",
      "Epoch 81/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0359 - mae: 0.1499\n",
      "Epoch 81: loss improved from 0.03622 to 0.03586, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0359 - mae: 0.1498\n",
      "Epoch 82/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0361 - mae: 0.1451\n",
      "Epoch 82: loss improved from 0.03586 to 0.03521, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0360 - mae: 0.1452\n",
      "Epoch 83/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0342 - mae: 0.1433\n",
      "Epoch 83: loss improved from 0.03521 to 0.03485, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0343 - mae: 0.1434\n",
      "Epoch 84/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0361 - mae: 0.1484\n",
      "Epoch 84: loss improved from 0.03485 to 0.03480, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0361 - mae: 0.1482\n",
      "Epoch 85/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0334 - mae: 0.1427\n",
      "Epoch 85: loss improved from 0.03480 to 0.03373, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0334 - mae: 0.1427\n",
      "Epoch 86/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0322 - mae: 0.1395\n",
      "Epoch 86: loss improved from 0.03373 to 0.03327, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0322 - mae: 0.1397\n",
      "Epoch 87/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0318 - mae: 0.1389\n",
      "Epoch 87: loss improved from 0.03327 to 0.03264, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0319 - mae: 0.1392\n",
      "Epoch 88/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0324 - mae: 0.1399\n",
      "Epoch 88: loss improved from 0.03264 to 0.03246, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0324 - mae: 0.1399\n",
      "Epoch 89/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0331 - mae: 0.1447\n",
      "Epoch 89: loss did not improve from 0.03246\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0331 - mae: 0.1446\n",
      "Epoch 90/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0335 - mae: 0.1432\n",
      "Epoch 90: loss did not improve from 0.03246\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0335 - mae: 0.1432\n",
      "Epoch 91/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0346 - mae: 0.1419\n",
      "Epoch 91: loss improved from 0.03246 to 0.03240, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0343 - mae: 0.1417\n",
      "Epoch 92/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0293 - mae: 0.1337\n",
      "Epoch 92: loss improved from 0.03240 to 0.03154, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0295 - mae: 0.1343\n",
      "Epoch 93/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0323 - mae: 0.1380\n",
      "Epoch 93: loss improved from 0.03154 to 0.03121, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0322 - mae: 0.1379\n",
      "Epoch 94/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0282 - mae: 0.1312\n",
      "Epoch 94: loss improved from 0.03121 to 0.03055, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0285 - mae: 0.1318\n",
      "Epoch 95/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0292 - mae: 0.1338\n",
      "Epoch 95: loss improved from 0.03055 to 0.03031, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0293 - mae: 0.1340\n",
      "Epoch 96/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0288 - mae: 0.1336\n",
      "Epoch 96: loss improved from 0.03031 to 0.03006, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0289 - mae: 0.1337\n",
      "Epoch 97/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0290 - mae: 0.1319\n",
      "Epoch 97: loss improved from 0.03006 to 0.02973, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0290 - mae: 0.1320\n",
      "Epoch 98/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0271 - mae: 0.1295\n",
      "Epoch 98: loss did not improve from 0.02973\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0274 - mae: 0.1301\n",
      "Epoch 99/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0311 - mae: 0.1374\n",
      "Epoch 99: loss improved from 0.02973 to 0.02881, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0308 - mae: 0.1368\n",
      "Epoch 100/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0271 - mae: 0.1294\n",
      "Epoch 100: loss improved from 0.02881 to 0.02872, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0272 - mae: 0.1295\n",
      "Epoch 101/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0293 - mae: 0.1325\n",
      "Epoch 101: loss improved from 0.02872 to 0.02868, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0292 - mae: 0.1324\n",
      "Epoch 102/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0274 - mae: 0.1291\n",
      "Epoch 102: loss did not improve from 0.02868\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0274 - mae: 0.1293\n",
      "Epoch 103/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0294 - mae: 0.1337\n",
      "Epoch 103: loss did not improve from 0.02868\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0294 - mae: 0.1337\n",
      "Epoch 104/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0281 - mae: 0.1301\n",
      "Epoch 104: loss did not improve from 0.02868\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0281 - mae: 0.1303\n",
      "Epoch 105/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0286 - mae: 0.1333\n",
      "Epoch 105: loss did not improve from 0.02868\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0287 - mae: 0.1334\n",
      "Epoch 106/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0287 - mae: 0.1292\n",
      "Epoch 106: loss improved from 0.02868 to 0.02823, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0287 - mae: 0.1293\n",
      "Epoch 107/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0281 - mae: 0.1297\n",
      "Epoch 107: loss improved from 0.02823 to 0.02729, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0280 - mae: 0.1296\n",
      "Epoch 108/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0264 - mae: 0.1298\n",
      "Epoch 108: loss improved from 0.02729 to 0.02687, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0265 - mae: 0.1297\n",
      "Epoch 109/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0268 - mae: 0.1292\n",
      "Epoch 109: loss did not improve from 0.02687\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0268 - mae: 0.1292\n",
      "Epoch 110/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0280 - mae: 0.1293\n",
      "Epoch 110: loss did not improve from 0.02687\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0279 - mae: 0.1291\n",
      "Epoch 111/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0255 - mae: 0.1247\n",
      "Epoch 111: loss improved from 0.02687 to 0.02600, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0256 - mae: 0.1249\n",
      "Epoch 112/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0249 - mae: 0.1259\n",
      "Epoch 112: loss improved from 0.02600 to 0.02524, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0250 - mae: 0.1258\n",
      "Epoch 113/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0256 - mae: 0.1250\n",
      "Epoch 113: loss did not improve from 0.02524\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0255 - mae: 0.1249\n",
      "Epoch 114/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0267 - mae: 0.1282\n",
      "Epoch 114: loss improved from 0.02524 to 0.02505, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0266 - mae: 0.1280\n",
      "Epoch 115/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0247 - mae: 0.1240\n",
      "Epoch 115: loss improved from 0.02505 to 0.02478, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0247 - mae: 0.1238\n",
      "Epoch 116/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0232 - mae: 0.1206\n",
      "Epoch 116: loss improved from 0.02478 to 0.02377, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0232 - mae: 0.1206\n",
      "Epoch 117/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0238 - mae: 0.1213\n",
      "Epoch 117: loss did not improve from 0.02377\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0238 - mae: 0.1212\n",
      "Epoch 118/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0239 - mae: 0.1207\n",
      "Epoch 118: loss did not improve from 0.02377\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0239 - mae: 0.1207\n",
      "Epoch 119/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0225 - mae: 0.1164\n",
      "Epoch 119: loss did not improve from 0.02377\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0227 - mae: 0.1169\n",
      "Epoch 120/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0247 - mae: 0.1213\n",
      "Epoch 120: loss did not improve from 0.02377\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0246 - mae: 0.1213\n",
      "Epoch 121/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0226 - mae: 0.1187\n",
      "Epoch 121: loss did not improve from 0.02377\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0227 - mae: 0.1190\n",
      "Epoch 122/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0226 - mae: 0.1180\n",
      "Epoch 122: loss improved from 0.02377 to 0.02325, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0226 - mae: 0.1181\n",
      "Epoch 123/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0233 - mae: 0.1195\n",
      "Epoch 123: loss did not improve from 0.02325\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0233 - mae: 0.1195\n",
      "Epoch 124/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0229 - mae: 0.1202\n",
      "Epoch 124: loss did not improve from 0.02325\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0230 - mae: 0.1203\n",
      "Epoch 125/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0228 - mae: 0.1193\n",
      "Epoch 125: loss did not improve from 0.02325\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0229 - mae: 0.1193\n",
      "Epoch 126/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0234 - mae: 0.1197\n",
      "Epoch 126: loss did not improve from 0.02325\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0235 - mae: 0.1200\n",
      "Epoch 127/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0225 - mae: 0.1181\n",
      "Epoch 127: loss improved from 0.02325 to 0.02299, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0226 - mae: 0.1182\n",
      "Epoch 128/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0237 - mae: 0.1189\n",
      "Epoch 128: loss improved from 0.02299 to 0.02171, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0236 - mae: 0.1187\n",
      "Epoch 129/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0197 - mae: 0.1098\n",
      "Epoch 129: loss improved from 0.02171 to 0.02159, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0199 - mae: 0.1104\n",
      "Epoch 130/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0191 - mae: 0.1073\n",
      "Epoch 130: loss improved from 0.02159 to 0.02069, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0193 - mae: 0.1079\n",
      "Epoch 131/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0210 - mae: 0.1138\n",
      "Epoch 131: loss did not improve from 0.02069\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0210 - mae: 0.1137\n",
      "Epoch 132/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0229 - mae: 0.1202\n",
      "Epoch 132: loss did not improve from 0.02069\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0227 - mae: 0.1194\n",
      "Epoch 133/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0213 - mae: 0.1141\n",
      "Epoch 133: loss improved from 0.02069 to 0.02048, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0212 - mae: 0.1139\n",
      "Epoch 134/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202 - mae: 0.1119\n",
      "Epoch 134: loss improved from 0.02048 to 0.02044, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0202 - mae: 0.1119\n",
      "Epoch 135/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0209 - mae: 0.1145\n",
      "Epoch 135: loss did not improve from 0.02044\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0210 - mae: 0.1145\n",
      "Epoch 136/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0214 - mae: 0.1139\n",
      "Epoch 136: loss did not improve from 0.02044\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0214 - mae: 0.1139\n",
      "Epoch 137/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0201 - mae: 0.1119\n",
      "Epoch 137: loss improved from 0.02044 to 0.02044, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0201 - mae: 0.1119\n",
      "Epoch 138/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0189 - mae: 0.1106\n",
      "Epoch 138: loss improved from 0.02044 to 0.01995, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0190 - mae: 0.1107\n",
      "Epoch 139/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0184 - mae: 0.1081\n",
      "Epoch 139: loss did not improve from 0.01995\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0186 - mae: 0.1086\n",
      "Epoch 140/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0188 - mae: 0.1094\n",
      "Epoch 140: loss improved from 0.01995 to 0.01936, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0189 - mae: 0.1094\n",
      "Epoch 141/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0180 - mae: 0.1048\n",
      "Epoch 141: loss improved from 0.01936 to 0.01921, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0181 - mae: 0.1050\n",
      "Epoch 142/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0178 - mae: 0.1049\n",
      "Epoch 142: loss improved from 0.01921 to 0.01854, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0179 - mae: 0.1051\n",
      "Epoch 143/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0187 - mae: 0.1060\n",
      "Epoch 143: loss did not improve from 0.01854\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0187 - mae: 0.1062\n",
      "Epoch 144/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0190 - mae: 0.1098\n",
      "Epoch 144: loss did not improve from 0.01854\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0190 - mae: 0.1098\n",
      "Epoch 145/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0178 - mae: 0.1029\n",
      "Epoch 145: loss did not improve from 0.01854\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0179 - mae: 0.1035\n",
      "Epoch 146/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0205 - mae: 0.1136\n",
      "Epoch 146: loss did not improve from 0.01854\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0205 - mae: 0.1136\n",
      "Epoch 147/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0204 - mae: 0.1113\n",
      "Epoch 147: loss did not improve from 0.01854\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0203 - mae: 0.1111\n",
      "Epoch 148/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0171 - mae: 0.1023\n",
      "Epoch 148: loss improved from 0.01854 to 0.01818, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0172 - mae: 0.1026\n",
      "Epoch 149/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0172 - mae: 0.1027\n",
      "Epoch 149: loss improved from 0.01818 to 0.01804, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0173 - mae: 0.1030\n",
      "Epoch 150/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0165 - mae: 0.0986\n",
      "Epoch 150: loss improved from 0.01804 to 0.01747, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0166 - mae: 0.0993\n",
      "Epoch 151/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0172 - mae: 0.1039\n",
      "Epoch 151: loss did not improve from 0.01747\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0172 - mae: 0.1040\n",
      "Epoch 152/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0175 - mae: 0.1027\n",
      "Epoch 152: loss improved from 0.01747 to 0.01716, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0174 - mae: 0.1027\n",
      "Epoch 153/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0183 - mae: 0.1060\n",
      "Epoch 153: loss did not improve from 0.01716\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0183 - mae: 0.1059\n",
      "Epoch 154/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0168 - mae: 0.1008\n",
      "Epoch 154: loss did not improve from 0.01716\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0169 - mae: 0.1011\n",
      "Epoch 155/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0163 - mae: 0.1016\n",
      "Epoch 155: loss improved from 0.01716 to 0.01705, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0163 - mae: 0.1017\n",
      "Epoch 156/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0155 - mae: 0.0982\n",
      "Epoch 156: loss improved from 0.01705 to 0.01665, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0156 - mae: 0.0984\n",
      "Epoch 157/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0170 - mae: 0.1033\n",
      "Epoch 157: loss improved from 0.01665 to 0.01660, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0170 - mae: 0.1031\n",
      "Epoch 158/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0166 - mae: 0.0991\n",
      "Epoch 158: loss did not improve from 0.01660\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0166 - mae: 0.0992\n",
      "Epoch 159/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0147 - mae: 0.0944\n",
      "Epoch 159: loss improved from 0.01660 to 0.01608, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0148 - mae: 0.0947\n",
      "Epoch 160/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0157 - mae: 0.0989\n",
      "Epoch 160: loss improved from 0.01608 to 0.01584, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0157 - mae: 0.0989\n",
      "Epoch 161/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0165 - mae: 0.1019\n",
      "Epoch 161: loss did not improve from 0.01584\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0165 - mae: 0.1018\n",
      "Epoch 162/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0154 - mae: 0.0979\n",
      "Epoch 162: loss did not improve from 0.01584\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0155 - mae: 0.0980\n",
      "Epoch 163/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0165 - mae: 0.0994\n",
      "Epoch 163: loss did not improve from 0.01584\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0165 - mae: 0.0995\n",
      "Epoch 164/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0151 - mae: 0.0982\n",
      "Epoch 164: loss did not improve from 0.01584\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0151 - mae: 0.0984\n",
      "Epoch 165/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0153 - mae: 0.0979\n",
      "Epoch 165: loss improved from 0.01584 to 0.01545, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0154 - mae: 0.0978\n",
      "Epoch 166/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0138 - mae: 0.0927\n",
      "Epoch 166: loss did not improve from 0.01545\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0139 - mae: 0.0930\n",
      "Epoch 167/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0148 - mae: 0.0937\n",
      "Epoch 167: loss improved from 0.01545 to 0.01530, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0148 - mae: 0.0941\n",
      "Epoch 168/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0161 - mae: 0.0980\n",
      "Epoch 168: loss did not improve from 0.01530\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0161 - mae: 0.0979\n",
      "Epoch 169/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0140 - mae: 0.0946\n",
      "Epoch 169: loss improved from 0.01530 to 0.01479, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0141 - mae: 0.0946\n",
      "Epoch 170/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0143 - mae: 0.0935\n",
      "Epoch 170: loss did not improve from 0.01479\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0144 - mae: 0.0936\n",
      "Epoch 171/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0153 - mae: 0.0973\n",
      "Epoch 171: loss did not improve from 0.01479\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0153 - mae: 0.0972\n",
      "Epoch 172/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0145 - mae: 0.0941\n",
      "Epoch 172: loss did not improve from 0.01479\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0146 - mae: 0.0944\n",
      "Epoch 173/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0143 - mae: 0.0924\n",
      "Epoch 173: loss did not improve from 0.01479\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0144 - mae: 0.0928\n",
      "Epoch 174/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0142 - mae: 0.0939\n",
      "Epoch 174: loss did not improve from 0.01479\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0143 - mae: 0.0943\n",
      "Epoch 175/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0150 - mae: 0.0953\n",
      "Epoch 175: loss improved from 0.01479 to 0.01453, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0150 - mae: 0.0953\n",
      "Epoch 176/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0148 - mae: 0.0956\n",
      "Epoch 176: loss improved from 0.01453 to 0.01445, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0148 - mae: 0.0954\n",
      "Epoch 177/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0151 - mae: 0.0965\n",
      "Epoch 177: loss improved from 0.01445 to 0.01413, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0150 - mae: 0.0963\n",
      "Epoch 178/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0152 - mae: 0.0973\n",
      "Epoch 178: loss improved from 0.01413 to 0.01401, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0151 - mae: 0.0971\n",
      "Epoch 179/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0128 - mae: 0.0902\n",
      "Epoch 179: loss improved from 0.01401 to 0.01386, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0128 - mae: 0.0903\n",
      "Epoch 180/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0142 - mae: 0.0927\n",
      "Epoch 180: loss improved from 0.01386 to 0.01368, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0142 - mae: 0.0927\n",
      "Epoch 181/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0130 - mae: 0.0887\n",
      "Epoch 181: loss improved from 0.01368 to 0.01359, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0131 - mae: 0.0890\n",
      "Epoch 182/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0138 - mae: 0.0918\n",
      "Epoch 182: loss improved from 0.01359 to 0.01334, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0137 - mae: 0.0917\n",
      "Epoch 183/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0136 - mae: 0.0912\n",
      "Epoch 183: loss did not improve from 0.01334\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0136 - mae: 0.0912\n",
      "Epoch 184/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0129 - mae: 0.0888\n",
      "Epoch 184: loss improved from 0.01334 to 0.01307, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0129 - mae: 0.0888\n",
      "Epoch 185/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0130 - mae: 0.0905\n",
      "Epoch 185: loss did not improve from 0.01307\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0130 - mae: 0.0905\n",
      "Epoch 186/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0131 - mae: 0.0893\n",
      "Epoch 186: loss did not improve from 0.01307\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0132 - mae: 0.0894\n",
      "Epoch 187/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0122 - mae: 0.0838\n",
      "Epoch 187: loss improved from 0.01307 to 0.01301, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0123 - mae: 0.0843\n",
      "Epoch 188/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0121 - mae: 0.0880\n",
      "Epoch 188: loss did not improve from 0.01301\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0122 - mae: 0.0882\n",
      "Epoch 189/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0132 - mae: 0.0914\n",
      "Epoch 189: loss improved from 0.01301 to 0.01295, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0132 - mae: 0.0911\n",
      "Epoch 190/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0121 - mae: 0.0861\n",
      "Epoch 190: loss did not improve from 0.01295\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0122 - mae: 0.0864\n",
      "Epoch 191/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0127 - mae: 0.0884\n",
      "Epoch 191: loss improved from 0.01295 to 0.01295, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0127 - mae: 0.0885\n",
      "Epoch 192/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0127 - mae: 0.0869\n",
      "Epoch 192: loss did not improve from 0.01295\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0128 - mae: 0.0871\n",
      "Epoch 193/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0126 - mae: 0.0895\n",
      "Epoch 193: loss did not improve from 0.01295\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0127 - mae: 0.0895\n",
      "Epoch 194/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0125 - mae: 0.0893\n",
      "Epoch 194: loss did not improve from 0.01295\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0125 - mae: 0.0894\n",
      "Epoch 195/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0130 - mae: 0.0890\n",
      "Epoch 195: loss did not improve from 0.01295\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0130 - mae: 0.0890\n",
      "Epoch 196/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0128 - mae: 0.0891\n",
      "Epoch 196: loss improved from 0.01295 to 0.01250, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0128 - mae: 0.0889\n",
      "Epoch 197/200\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0113 - mae: 0.0822\n",
      "Epoch 197: loss improved from 0.01250 to 0.01244, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0114 - mae: 0.0828\n",
      "Epoch 198/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0121 - mae: 0.0854\n",
      "Epoch 198: loss improved from 0.01244 to 0.01234, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0122 - mae: 0.0855\n",
      "Epoch 199/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0135 - mae: 0.0909\n",
      "Epoch 199: loss improved from 0.01234 to 0.01186, saving model to best_lstm_model_reg.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0134 - mae: 0.0905\n",
      "Epoch 200/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0109 - mae: 0.0812\n",
      "Epoch 200: loss did not improve from 0.01186\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0110 - mae: 0.0815\n"
     ]
    }
   ],
   "source": [
    "# X_windows.shape = (1343, 130, 12)\n",
    "# y_windows.shape = (1343,)\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X_train = X_windows[:1000,:,:]\n",
    "X_test  = X_windows[1000:,:,:]\n",
    "y_train = y_windows[:1000]\n",
    "y_test  = y_windows[1000:]\n",
    "\n",
    "# Define the callback to save the best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_lstm_model_reg.keras',  # Filepath to save the best model\n",
    "    monitor='loss',                        # Metric to monitor\n",
    "    save_best_only=True,                   # Save only the best model\n",
    "    verbose=1                              # Print messages when saving\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model with the callback\n",
    "history = final_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[checkpoint_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2515407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3386447381153.95"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_scaler.inverse_transform(final_model.predict(X_test))\n",
    "y_test = y_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "mae    = mean_absolute_error(y_test, y_pred)\n",
    "mae"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

